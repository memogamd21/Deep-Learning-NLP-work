{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"this is a multi sentence doc. this is the second one. end sentence is here\"\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sents = sent_tokenize(sent)\n",
    "for i in range(len(sents)):\n",
    "    sents[i] += '</s>'\n",
    "    sents[i] = '<s>' + sents[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokens = [token  for sent in sents for token in WordPunctTokenizer().tokenize(sent)]\n",
    "mwtokenizer = nltk.MWETokenizer(separator='')\n",
    "mwtokenizer.add_mwe(('<', 's', '>'))\n",
    "mwtokenizer.add_mwe(('</','s', '>'))\n",
    "final_tokens = mwtokenizer.tokenize(tokens)\n",
    "final_tokens = [tk for tk in final_tokens if not(len(tk) < 3)]\n",
    "final_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = ['no', 'no', 'good', 'fish', 'goes', 'anywhere', 'without', 'a', 'purpose', '!']\n",
    "text2 = ['no', 'no','good', 'purpose', 'likes', 'to', 'fish', 'fish', 'anywhere', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = ngrams(text1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bigrams:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist.most_common(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams2 = ngrams(text2,2)\n",
    "fdist.update(bigrams2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('anywhere', 'without'),\n",
       " ('fish', 'goes'),\n",
       " ('goes', 'anywhere'),\n",
       " ('good', 'fish')]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.corpus import webtext, stopwords\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "sset = set(stopwords.words('english'))\n",
    "stops_filter = lambda w: len(w) < 3 or w in sset\n",
    "# tokens=[t.lower() for t in webtext.words('grail.txt')]\n",
    "tokens = ['no', 'no', 'good', 'fish', 'goes', 'anywhere', 'without', 'a', 'purpose', '!']\n",
    "words=BigramCollocationFinder.from_words(tokens)\n",
    "words.apply_word_filter(stops_filter)\n",
    "# words.apply_freq_filter(3)\n",
    "words.nbest(BigramAssocMeasures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.word_fd.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(('good', 'fish'), 1), (('fish', 'goes'), 1), (('goes', 'anywhere'), 1), (('anywhere', 'without'), 1)])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.ngram_fd.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "text1=\"Hardwork is the key to success. Never give up!\"\n",
    "word = nltk.wordpunct_tokenize(text1)\n",
    "finder = BigramCollocationFinder.from_words(word)\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "value = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "sorted(bigram for bigram, score in value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Hello how are you doing ? Hello how I hope you find the book interesting\"\n",
    "tokens=nltk.wordpunct_tokenize(text)\n",
    "words=BigramCollocationFinder.from_words(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = words.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = ['no', 'no', 'good', 'fish', 'goes', 'anywhere', 'without', 'a', 'porpoise', '!']\n",
    "text2 = ['no', 'good', 'porpoise', 'likes', 'to', 'fish', 'fish', 'anywhere', '.']\n",
    "fd1 = nltk.FreqDist(text1)  ## FreqDist can take a list of bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LaplaceProbDist(fd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12903225806451613"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.prob('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3870967741935484"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.discount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
