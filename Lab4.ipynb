{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \"intention\"\n",
    "Y = \"execution\"\n",
    "mem = - np.ones((len(X)+1,len(Y)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MED recuresion solved by instructor\n",
    "\n",
    "def solve(i, j):\n",
    "    if i==0:\n",
    "        mem[i,j] = j\n",
    "        return j\n",
    "    if j ==0:\n",
    "        mem[i,j] = i\n",
    "        return i\n",
    "    if mem[i,j] != -1:\n",
    "        return mem[i,j]\n",
    "    mem[i,j] = min(solve(i-1,j)+1, solve(i,j-1)+1, solve(i-1, j-1)+2 if X[i-1]!=Y[j-1] else solve(i-1, j-1))\n",
    "    return mem[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem = - np.ones((len(X)+1,len(Y)+1))\n",
    "solve(len(X),len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n",
       "       [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  6.,  7.,  8.],\n",
       "       [ 2.,  3.,  4.,  5.,  6.,  7.,  8.,  7.,  8.,  7.],\n",
       "       [ 3.,  4.,  5.,  6.,  7.,  8.,  7.,  8.,  9.,  8.],\n",
       "       [ 4.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.,  9.],\n",
       "       [ 5.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 10.],\n",
       "       [ 6.,  5.,  6.,  7.,  8.,  9.,  8.,  9., 10., 11.],\n",
       "       [ 7.,  6.,  7.,  8.,  9., 10.,  9.,  8.,  9., 10.],\n",
       "       [ 8.,  7.,  8.,  9., 10., 11., 10.,  9.,  8.,  9.],\n",
       "       [ 9.,  8.,  9., 10., 11., 12., 11., 10.,  9.,  8.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### iterative solution should be solved by students grade: 30%\n",
    "def solve(N, M):\n",
    "    for i in range(N+1):\n",
    "        mem[i,0] = i\n",
    "    for j in range(M+1):\n",
    "        mem[0,j] = j\n",
    "    for i in range(1,N+1):\n",
    "        for j in range(1,M+1):\n",
    "            mem[i,j] = min(mem[i-1,j]+1, mem[i,j-1]+1, mem[i-1, j-1]+2 if X[i-1]!=Y[j-1] else mem[i-1, j-1])\n",
    "    return mem[N,M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem = - np.ones((len(X)+1,len(Y)+1))\n",
    "solve(len(X),len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n",
       "       [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  6.,  7.,  8.],\n",
       "       [ 2.,  3.,  4.,  5.,  6.,  7.,  8.,  7.,  8.,  7.],\n",
       "       [ 3.,  4.,  5.,  6.,  7.,  8.,  7.,  8.,  9.,  8.],\n",
       "       [ 4.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.,  9.],\n",
       "       [ 5.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 10.],\n",
       "       [ 6.,  5.,  6.,  7.,  8.,  9.,  8.,  9., 10., 11.],\n",
       "       [ 7.,  6.,  7.,  8.,  9., 10.,  9.,  8.,  9., 10.],\n",
       "       [ 8.,  7.,  8.,  9., 10., 11., 10.,  9.,  8.,  9.],\n",
       "       [ 9.,  8.,  9., 10., 11., 12., 11., 10.,  9.,  8.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### naive backtrace solved by instructor\n",
    "\n",
    "def path(i, j):\n",
    "    print(X[:i])\n",
    "    print(Y[:j])\n",
    "    if i==0:\n",
    "        return\n",
    "    if j ==0:\n",
    "        return\n",
    "    sol = mem[i,j]\n",
    "    \n",
    "    if sol == mem[i-1,j-1]+2:\n",
    "        print('sub')\n",
    "        path(i-1,j-1)\n",
    "        return\n",
    "    if sol == mem[i-1,j-1] and X[i-1] == Y[j-1]:\n",
    "        print('nothing')\n",
    "        path(i-1,j-1)\n",
    "        return\n",
    "    if sol == mem[i-1,j]+1:\n",
    "        print('delete')\n",
    "        path(i-1,j)\n",
    "        return\n",
    "    if sol == mem[i,j-1]+1:\n",
    "        print('insert')\n",
    "        path(i,j-1)\n",
    "        return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intention\n",
      "execution\n",
      "nothing\n",
      "intentio\n",
      "executio\n",
      "nothing\n",
      "intenti\n",
      "executi\n",
      "nothing\n",
      "intent\n",
      "execut\n",
      "nothing\n",
      "inten\n",
      "execu\n",
      "sub\n",
      "inte\n",
      "exec\n",
      "insert\n",
      "inte\n",
      "exe\n",
      "nothing\n",
      "int\n",
      "ex\n",
      "sub\n",
      "in\n",
      "e\n",
      "sub\n",
      "i\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path(9,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-Levenshtein\n",
    "# powerfull MED library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### similarity based on applications\n",
    "# https://www.nltk.org/api/nltk.metrics.html#module-nltk.metrics.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "8\n",
      "0.375\n",
      "0.58125\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.metrics import *\n",
    "\n",
    "X = \"intention\"\n",
    "Y = \"execution\"\n",
    "print(binary_distance(X,Y))\n",
    "print(edit_distance(X,Y, substitution_cost = 2))\n",
    "print(jaccard_distance(set(X),set(Y)))\n",
    "print(masi_distance(set(X),set(Y))) # created to evaluate annotators performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jaccard similarity is the opposite of distance\n",
    "def jaccard_similarity(X,Y):\n",
    "    return len((X) & (Y)) / len((X) | (Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    }
   ],
   "source": [
    "print(jaccard_similarity(set(X),set(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading gutenberg: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 7811 samples and 192427 outcomes>\n",
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had been supplied\n",
      "by an excellent woman as governess, who had fallen little short\n",
      "of a mother in affection.\n",
      "\n",
      "Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\n",
      "less as a governess than a friend, very fond of both daughters,\n",
      "but particularly of Emma.  Between _them_ it was more the intimacy\n",
      "of sisters.  Even before Miss Taylor had ceased to hold the nominal\n",
      "office of governess, the mildness of her temper had hardly allowed\n",
      "her to impose any restraint; and the shadow of authority being\n",
      "now long passed away, they had been living together as friend and\n",
      "friend very mutually attached, and Emma doing just what she liked;\n",
      "highly esteeming Miss Taylor's judgment, but directed chiefly by\n",
      "her own.\n",
      "\n",
      "The real evils, indeed, of Emma's situation were the power of having\n",
      "rather too much her own way, and a disposition to think a little\n",
      "too well of herself; these were the disadvantages which threatened\n",
      "alloy to her many enjoyments.  The danger, however, was at present\n",
      "so unperceived, that they did not by any means rank as misfortunes\n",
      "with her.\n",
      "\n",
      "Sorrow came--a gentle sorrow--but not at all in the shape of any\n",
      "disagreeable consciousness.--Miss Taylor married.  It was Miss\n",
      "Taylor's loss which first brought grief.  It was on the wedding-day\n",
      "of this beloved friend that Emma first sat in mournful thought\n",
      "of any continuance.\n",
      "a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11, 379, 217, 337)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### practical exercise\n",
    "\n",
    "import nltk\n",
    "# https://www.nltk.org/book/\n",
    "\n",
    "# https://www.nltk.org/book/ch02.html\n",
    "# available corpora in gutenberg\n",
    "# print(nltk.corpus.gutenberg.fileids())\n",
    "\n",
    "# https://docs.huihoo.com/nltk/0.9.5/api/nltk.corpus.reader.plaintext.PlaintextCorpusReader-class.html\n",
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "\n",
    "# # http://www.nltk.org/api/nltk.html#nltk.text.Text\n",
    "emma = nltk.Text(emma)\n",
    "\n",
    "# # print words frequency\n",
    "print(emma.vocab())\n",
    "\n",
    "emmas = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
    "corpus = emmas[:1927]\n",
    "sentences = nltk.sent_tokenize(corpus)\n",
    "words = nltk.word_tokenize(corpus)\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "filtered_text = []\n",
    "for w in words:\n",
    "    if w not in stop_words:\n",
    "        filtered_text.append(w)\n",
    "print(corpus)\n",
    "toke = nltk.RegexpTokenizer('\\w+')\n",
    "toks = toke.tokenize(corpus)\n",
    "distances = []\n",
    "for i in range(len(words)):\n",
    "    counter = 0\n",
    "    for j in range(len(words)):\n",
    "        distance = edit_distance(words[i],words[j], substitution_cost = 2)\n",
    "        counter += distance\n",
    "    distances.append(counter)\n",
    "np.asarray(distances)\n",
    "index = np.argmin(distances)\n",
    "print(words[index])\n",
    "len(sentences),len(words),len(filtered_text),len(toks)\n",
    "# find:\n",
    "# no. of sentences\n",
    "# no. of tokens\n",
    "# no. of tokens after stop words removal\n",
    "# no. of tokens after punctuation removal\n",
    "# no. of tokens after regexReplacer removal\n",
    "# find the most similar token relative to the whole tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import replacers as rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reep = rep.RegexpReplacer()\n",
    "toop = reep.replace(corpus)\n",
    "len(nltk.WordPunctTokenizer().tokenize(toop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 0.5, 1.0, 0.5]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "tokes = nltk.WordPunctTokenizer()\n",
    "text = \"I want to travel to Cuba\"\n",
    "tokens = tokes.tokenize(text)\n",
    "bigrams = []\n",
    "for i in range(len(tokens)-1):\n",
    "    bigram = (tokens[i], tokens[i+1])\n",
    "    bigrams.append(bigram)\n",
    "uniques = list(set(tokens))\n",
    "def compute_freqs(uniq,text):\n",
    "    probs = []\n",
    "    for m in range(len(uniq)):\n",
    "        count = 0\n",
    "        for t in range(len(text)):\n",
    "            if uniq[m] == text[t]:\n",
    "                count +=1\n",
    "        probs.append(count)\n",
    "    return probs\n",
    "probs = compute_freqs(uniques,tokens)\n",
    "bigram_probs = [0,0,0,0,0]\n",
    "counts = []\n",
    "for h in range (len(bigrams)):\n",
    "    w1,w2 = bigrams[h]\n",
    "    counter = 0\n",
    "    for j in range(len(tokens)-1):\n",
    "        if w1 == tokens[j] and w2 == tokens[j+1]:\n",
    "            counter += 1\n",
    "        else:\n",
    "            counter = counter\n",
    "    counts.append(counter)\n",
    "counts\n",
    "bigram_probs[0] = counts[0]/probs[0]\n",
    "bigram_probs[1] = counts[1]/probs[3]\n",
    "bigram_probs[2] = counts[2]/probs[1]\n",
    "bigram_probs[3] = counts[3]/probs[4]\n",
    "bigram_probs[4] = counts[4]/probs[1]\n",
    "bigram_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'to', 'Cuba', 'want', 'travel']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
